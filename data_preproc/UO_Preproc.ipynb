{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7d0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.io import loadmat\n",
    "import torch\n",
    "import urllib.request\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93920a14",
   "metadata": {},
   "source": [
    "# Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f13d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5995af",
   "metadata": {},
   "source": [
    "# Download and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfbab421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/v43hmbwxpm-1.zip\n",
      "Extracting UO.zip\n"
     ]
    }
   ],
   "source": [
    "# UO bearings dataset\n",
    "UO_links = {\n",
    "    'UO': 'https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/v43hmbwxpm-1.zip'\n",
    "}\n",
    "\n",
    "def download_and_extract(file_name, url, folder_path, dtype, extract_function):\n",
    "    while True:\n",
    "        try:\n",
    "            print(f\"Downloading {url}\")\n",
    "            urllib.request.urlretrieve(url, os.path.join(folder_path, f'{file_name}{dtype}'))\n",
    "            print(f'Extracting {file_name}{dtype}')\n",
    "            extract_function(folder_path, file_name)\n",
    "            break  # Exit the loop if the download is successful\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {url}: {e}\")\n",
    "            \n",
    "def extract_zip(folder, file_name):\n",
    "    with zipfile.ZipFile(os.path.join(folder, f'{file_name}.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.join(folder, file_name))\n",
    "        \n",
    "# Download & Extract UO dataset\n",
    "folder_path = os.path.join(os.getcwd(), 'UO')\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "for file_name, url_link in UO_links.items():\n",
    "    if not os.path.exists(os.path.join(folder_path, file_name)):\n",
    "        download_and_extract(file_name, url_link, folder_path, '.zip', extract_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154f1958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17577, 2, 1024]) torch.Size([17577])\n",
      "torch.Size([17577, 2, 1024]) torch.Size([17577])\n",
      "torch.Size([17577, 2, 1024]) torch.Size([17577])\n",
      "torch.Size([17577, 2, 1024]) torch.Size([17577])\n"
     ]
    }
   ],
   "source": [
    "domain_A = {\n",
    "    0: ['H-A-1.mat', 'H-A-2.mat', 'H-A-3.mat'],\n",
    "    1: ['I-A-1.mat', 'I-A-2.mat', 'I-A-3.mat'],\n",
    "    3: ['O-A-1.mat', 'O-A-2.mat', 'O-A-3.mat']\n",
    "}\n",
    "\n",
    "domain_B = {\n",
    "    0: ['H-B-1.mat', 'H-B-2.mat', 'H-B-3.mat'],\n",
    "    1: ['I-B-1.mat', 'I-B-2.mat', 'I-B-3.mat'],\n",
    "    3: ['O-B-1.mat', 'O-B-2.mat', 'O-B-3.mat']\n",
    "}\n",
    "\n",
    "domain_C = {\n",
    "    0: ['H-C-1.mat', 'H-C-2.mat', 'H-C-3.mat'],\n",
    "    1: ['I-C-1.mat', 'I-C-2.mat', 'I-C-3.mat'],\n",
    "    3: ['O-C-1.mat', 'O-C-2.mat', 'O-C-3.mat']\n",
    "}\n",
    "\n",
    "domain_D = {\n",
    "    0: ['H-D-1.mat', 'H-D-2.mat', 'H-D-3.mat'],\n",
    "    1: ['I-D-1.mat', 'I-D-2.mat', 'I-D-3.mat'],\n",
    "    3: ['O-D-1.mat', 'O-D-2.mat', 'O-D-3.mat']\n",
    "}\n",
    "\n",
    "folder_path = os.path.join(os.getcwd(), \"UO\", \"UO\")\n",
    "\n",
    "def read_dict(mat_dict):\n",
    "    x, y = [], []\n",
    "    for label, file_list in mat_dict.items():\n",
    "        x_tensor, y_tensor = read_list(file_list, label)\n",
    "        x.append(x_tensor)\n",
    "        y.append(y_tensor)\n",
    "        \n",
    "    x = torch.cat(x, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    \n",
    "    return x, y\n",
    "        \n",
    "def read_list(file_list, label):\n",
    "    x, y = [], []\n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        data = loadmat(file_path)\n",
    "        channel_1, channel_2 = data['Channel_1'], data['Channel_2']\n",
    "        \n",
    "        combined_channels = np.stack((channel_1.squeeze(), channel_2.squeeze()), axis=0)\n",
    "        combined_tensor = torch.tensor(combined_channels)\n",
    "        \n",
    "        sample_tensor = sliding_window_subsample(combined_tensor, window_size=1024, step=1024)\n",
    "        label_tensor = labels = torch.full((sample_tensor.shape[0],), label)\n",
    "        x.append(sample_tensor)\n",
    "        y.append(label_tensor)\n",
    "        \n",
    "    x = torch.cat(x, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    \n",
    "    return x, y\n",
    "        \n",
    "def sliding_window_subsample(tensor, window_size=1024, step=1024):\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    return tensor.unfold(2, window_size, step).transpose(0, 1).transpose(1, 2).squeeze(0)\n",
    "\n",
    "A_x, A_y = read_dict(domain_A)\n",
    "B_x, B_y = read_dict(domain_B)\n",
    "C_x, C_y = read_dict(domain_C)\n",
    "D_x, D_y = read_dict(domain_D)\n",
    "\n",
    "print(A_x.shape, A_y.shape)\n",
    "print(B_x.shape, B_y.shape)\n",
    "print(C_x.shape, C_y.shape)\n",
    "print(D_x.shape, D_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beba76f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10546, 2, 1024]) torch.Size([10546])\n",
      "torch.Size([3515, 2, 1024]) torch.Size([3515])\n",
      "torch.Size([3516, 2, 1024]) torch.Size([3516])\n",
      "torch.Size([10546, 2, 1024]) torch.Size([10546])\n",
      "torch.Size([3515, 2, 1024]) torch.Size([3515])\n",
      "torch.Size([3516, 2, 1024]) torch.Size([3516])\n",
      "torch.Size([10546, 2, 1024]) torch.Size([10546])\n",
      "torch.Size([3515, 2, 1024]) torch.Size([3515])\n",
      "torch.Size([3516, 2, 1024]) torch.Size([3516])\n",
      "torch.Size([10546, 2, 1024]) torch.Size([10546])\n",
      "torch.Size([3515, 2, 1024]) torch.Size([3515])\n",
      "torch.Size([3516, 2, 1024]) torch.Size([3516])\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(x, y): # Split the tensor into training, validation and testing\n",
    "    dataset = torch.utils.data.TensorDataset(x, y) # Combine x and y to ensure both are split in the same way\n",
    "    \n",
    "    total_size = len(dataset)\n",
    "    train_size = int(0.6 * total_size)\n",
    "    val_size = int(0.2 * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "\n",
    "    # Split the dataset\n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "    \n",
    "    # Split x and y to maintain consistency with other dataset\n",
    "    train = split_xy(train_dataset)\n",
    "    val = split_xy(val_dataset)\n",
    "    test = split_xy(test_dataset)\n",
    "    \n",
    "    return train, val, test \n",
    "\n",
    "# Split x and y to maintain consistency with other dataset\n",
    "def split_xy(dataset):\n",
    "    x, y = [], []\n",
    "    for x_tensor, y_tensor in dataset:\n",
    "        x.append(x_tensor)\n",
    "        y.append(y_tensor)\n",
    "    # Convert lists to tensors\n",
    "    x = torch.stack(x)\n",
    "    y = torch.stack(y)\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "    return {\"samples\": x,  \"labels\": y}\n",
    "\n",
    "train_A, val_A, test_A = train_test_split(A_x, A_y)\n",
    "train_B, val_B, test_B = train_test_split(B_x, B_y)\n",
    "train_C, val_C, test_C = train_test_split(C_x, C_y)\n",
    "train_D, val_D, test_D = train_test_split(D_x, D_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6451093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parent directory\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "uo_dir = os.path.join(parent_dir, \"dataset\", \"UO\")\n",
    "\n",
    "# Save the datasets\n",
    "torch.save(train_A, os.path.join(uo_dir, 'train_U1.pt'))\n",
    "torch.save(val_A, os.path.join(uo_dir, 'val_U1.pt'))\n",
    "torch.save(test_A, os.path.join(uo_dir, 'test_U1.pt'))\n",
    "\n",
    "torch.save(train_B, os.path.join(uo_dir, 'train_U2.pt'))\n",
    "torch.save(val_B, os.path.join(uo_dir, 'val_U2.pt'))\n",
    "torch.save(test_B, os.path.join(uo_dir, 'test_U2.pt'))\n",
    "\n",
    "torch.save(train_C, os.path.join(uo_dir, 'train_U3.pt'))\n",
    "torch.save(val_C, os.path.join(uo_dir, 'val_U3.pt'))\n",
    "torch.save(test_C, os.path.join(uo_dir, 'test_U3.pt'))\n",
    "\n",
    "torch.save(train_D, os.path.join(uo_dir, 'train_U4.pt'))\n",
    "torch.save(val_D, os.path.join(uo_dir, 'val_U4.pt'))\n",
    "torch.save(test_D, os.path.join(uo_dir, 'test_U4.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
