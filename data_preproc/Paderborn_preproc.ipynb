{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9051fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c6e2d",
   "metadata": {},
   "source": [
    "# DataFolder Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a2fcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEALTHY BEARINGS\n",
      "  Folder_Name   Damage\n",
      "0        K001  Healthy\n",
      "1        K002  Healthy\n",
      "2        K003  Healthy\n",
      "3        K004  Healthy\n",
      "4        K005  Healthy\n",
      "5        K006  Healthy\n"
     ]
    }
   ],
   "source": [
    "healthy_dict = {\n",
    "    \"Folder_Name\": [\"K001\", \"K002\", \"K003\", \"K004\", \"K005\", \"K006\"],\n",
    "    \"Damage\": [\"Healthy\", \"Healthy\", \"Healthy\", \"Healthy\", \"Healthy\", \"Healthy\"]\n",
    "}\n",
    "healthy_df = pd.DataFrame(healthy_dict)\n",
    "print(\"HEALTHY BEARINGS\")\n",
    "print(healthy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727673d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTIFICIAL DAMAGES\n",
      "   Folder_Name Damage\n",
      "0         KA01  Outer\n",
      "1         KA03  Outer\n",
      "2         KA05  Outer\n",
      "3         KA06  Outer\n",
      "4         KA07  Outer\n",
      "5         KA09  Outer\n",
      "6         KI01  Inner\n",
      "7         KI03  Inner\n",
      "8         KI05  Inner\n",
      "9         KI07  Inner\n",
      "10        KI08  Inner\n"
     ]
    }
   ],
   "source": [
    "artificial_dict = {\n",
    "    \"Folder_Name\": [\"KA01\", \"KA03\", \"KA05\", \"KA06\", \"KA07\", \"KA09\", \"KI01\", \"KI03\", \"KI05\", \"KI07\", \"KI08\"],\n",
    "    \"Damage\": [\"Outer\", \"Outer\", \"Outer\", \"Outer\", \"Outer\", \"Outer\", \"Inner\", \"Inner\", \"Inner\", \"Inner\", \"Inner\"]\n",
    "}\n",
    "artificial_df = pd.DataFrame(artificial_dict)\n",
    "print(\"ARTIFICIAL DAMAGES\")\n",
    "print(artificial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df4a0ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL DAMAGES\n",
      "   Folder_Name Damage\n",
      "0         KA04  Outer\n",
      "1         KA15  Outer\n",
      "2         KA16  Outer\n",
      "3         KA22  Outer\n",
      "4         KA30  Outer\n",
      "5         KI04  Inner\n",
      "6         KI14  Inner\n",
      "7         KI16  Inner\n",
      "8         KI17  Inner\n",
      "9         KI18  Inner\n",
      "10        KI21  Inner\n"
     ]
    }
   ],
   "source": [
    "real_dict = {\n",
    "    \"Folder_Name\": [\"KA04\", \"KA15\", \"KA16\", \"KA22\", \"KA30\", \"KI04\", \"KI14\", \"KI16\", \"KI17\", \"KI18\", \"KI21\"],\n",
    "    \"Damage\": [\"Outer\", \"Outer\", \"Outer\", \"Outer\", \"Outer\", \"Inner\", \"Inner\", \"Inner\", \"Inner\", \"Inner\", \"Inner\"]\n",
    "}\n",
    "real_df = pd.DataFrame(real_dict)\n",
    "print(\"REAL DAMAGES\")\n",
    "print(real_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c719471",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf73f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"raw_data/Paderborn_university\")\n",
    "N_POINTS = 249600 #? 64k Sampling rate for 3.9 seconds\n",
    "domains = {\"Normal\": \"N15_M07_F10\", \"Rotate\": \"N09_M07_F10\", \"Load\": \"N15_M01_F10\", \"Radial\": \"N15_M07_F04\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5038bc89",
   "metadata": {},
   "source": [
    "# Split files into different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d230ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificial_dataset = [\"K001\", \"K002\", \"K003\", \"K004\", \"K005\", \"K006\",\n",
    "#                       \"KA01\", \"KA03\", \"KA05\", \"KA06\", \"KA07\", \"KA09\", \"KI01\", \"KI03\", \"KI05\", \"KI07\", \"KI08\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f565c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_dataset = [\"K001\",\n",
    "                      \"KA01\", \"KA03\", \"KA05\", \"KA07\", \"KI01\", \"KI03\", \"KI07\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebeb4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_dataset = [\"K001\", \"K002\", \"K003\", \"K004\", \"K005\", \"K006\",\n",
    "#                \"KA04\", \"KA15\", \"KA16\", \"KA22\", \"KA30\", \"KI14\", \"KI16\", \"KI17\", \"KI18\", \"KI21\"] # KI04 was removed because it is a duplicate of KI14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e20426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset = [\"K001\",\n",
    "               \"KA04\", \"KB23\", \"KB27\", \"KI04\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c7449",
   "metadata": {},
   "source": [
    "# Load datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2064609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_list):\n",
    "    #* This function will be responsible for extracting & label the data from the list defined above\n",
    "    #* Each of folder should contain 4 conditions with 20 measurements each\n",
    "    \n",
    "    #? The array shape is defined here as we can calculate the total number of samples which allows us to avoid using np.concatenate\n",
    "    #? This prevents np from copying the large array everytime it concatenates/update its value\n",
    "    \n",
    "    Normal = {\"x\": np.zeros((len(dataset_list) * 20, N_POINTS)), \"y\": np.zeros(len(dataset_list) * 20)}\n",
    "    Rotate = {\"x\": np.zeros((len(dataset_list) * 20, N_POINTS)), \"y\": np.zeros(len(dataset_list) * 20)}\n",
    "    Load = {\"x\": np.zeros((len(dataset_list) * 20, N_POINTS)), \"y\": np.zeros(len(dataset_list) * 20)}\n",
    "    Radial = {\"x\": np.zeros((len(dataset_list) * 20, N_POINTS)), \"y\": np.zeros(len(dataset_list) * 20)}\n",
    "    \n",
    "    for label, foldername in enumerate(dataset_list):\n",
    "        #? Each gear is assumed to be a class\n",
    "        folder_path = os.path.join(data_dir, foldername)\n",
    "        \n",
    "        #? List with all .mat file's path in folder_path\n",
    "        #? file_path should take the form cwd/raw_data/Paderborn_university/N09_M07_F10_K001_1.mat or other values\n",
    "        file_path_list = glob(os.path.join(folder_path, \"*.mat\"))\n",
    "        \n",
    "        Normal_files = [file for file in file_path_list if \"N15_M07_F10\" in file]\n",
    "        Rotate_files = [file for file in file_path_list if \"N09_M07_F10\" in file]\n",
    "        Load_files = [file for file in file_path_list if \"N15_M01_F10\" in file]\n",
    "        Radial_files = [file for file in file_path_list if \"N15_M07_F04\" in file]\n",
    "        \n",
    "        combined = zip(Normal_files, Rotate_files, Load_files, Radial_files)\n",
    "        \n",
    "        for i, (Normal_file, Rotate_file, Load_file, Radial_file) in enumerate(combined):\n",
    "            # Get vibration data\n",
    "            Normal_vibration = load_mat(Normal_file)\n",
    "            Rotate_vibration = load_mat(Rotate_file)\n",
    "            Load_vibration = load_mat(Load_file)\n",
    "            Radial_vibration = load_mat(Radial_file)\n",
    "\n",
    "            sample_id = (label * 20) + i\n",
    "\n",
    "            Normal[\"x\"][sample_id] = Normal_vibration\n",
    "            Normal[\"y\"][sample_id] = label\n",
    "\n",
    "            Rotate[\"x\"][sample_id] = Rotate_vibration\n",
    "            Rotate[\"y\"][sample_id] = label\n",
    "\n",
    "            Load[\"x\"][sample_id] = Load_vibration\n",
    "            Load[\"y\"][sample_id] = label\n",
    "\n",
    "            Radial[\"x\"][sample_id] = Radial_vibration\n",
    "            Radial[\"y\"][sample_id] = label\n",
    "            \n",
    "    Normal[\"x\"],  Normal[\"y\"] = torch.from_numpy(Normal[\"x\"]), torch.from_numpy(Normal[\"y\"])\n",
    "    Rotate[\"x\"],  Rotate[\"y\"] = torch.from_numpy(Rotate[\"x\"]), torch.from_numpy(Rotate[\"y\"])\n",
    "    Load[\"x\"],  Load[\"y\"] = torch.from_numpy(Load[\"x\"]), torch.from_numpy(Load[\"y\"])\n",
    "    Radial[\"x\"],  Radial[\"y\"] = torch.from_numpy(Radial[\"x\"]), torch.from_numpy(Radial[\"y\"])\n",
    "              \n",
    "    return Normal, Rotate, Load, Radial\n",
    "              \n",
    "def load_mat(mat_file):\n",
    "    #* Get the file name without .mat extension\n",
    "    #? Will be used to get the relevant data when loading the mat file\n",
    "    file_name = os.path.splitext(os.path.basename(mat_file))[0]\n",
    "    \n",
    "    mat_file_array = loadmat(mat_file)\n",
    "    #* Get the vibration data\n",
    "    #? vibration_data should be an array of shape (1, N_POINTS)\n",
    "    vibration_data = mat_file_array[file_name][\"Y\"][0][0][0][6][2][:,0:N_POINTS]\n",
    "    vibration_data = np.array(vibration_data)\n",
    "    \n",
    "    return vibration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "574d26c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[-0.0488,  0.2167,  0.2350,  ..., -0.0488,  0.3662, -0.1526],\n",
      "        [ 0.1587,  0.0641, -0.0824,  ..., -0.2594, -0.2014, -0.0641],\n",
      "        [-0.3204, -0.3845, -0.2655,  ...,  0.1495,  0.2167,  0.2838],\n",
      "        ...,\n",
      "        [ 0.5188,  0.3876,  0.4089,  ...,  0.2808,  0.1587,  0.2289],\n",
      "        [ 0.2655,  0.2075,  0.0671,  ..., -0.1251, -0.1617, -0.2563],\n",
      "        [-0.2258, -0.3754, -0.0732,  ...,  0.4486,  0.7812,  0.3967]],\n",
      "       dtype=torch.float64), 'y': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
      "        4., 4., 4., 4., 4., 4., 4., 4., 4., 4.], dtype=torch.float64)}\n",
      "torch.Size([100, 249600])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "Real_Normal, Real_Rotate, Real_Load, Real_Radial = load_data(real_dataset)\n",
    "Artificial_Normal, Artificial_Rotate, Artificial_Load, Artificial_Radial = load_data(artificial_dataset)\n",
    "\n",
    "print(Real_Normal)\n",
    "print(Real_Normal[\"x\"].shape)\n",
    "print(Real_Normal[\"y\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb6df18",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "266476ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS ###\n",
    "SAMPLE_LEN = 1024\n",
    "STRIDE = SAMPLE_LEN #! NO overlap\n",
    "TEST_SIZE = 0.2\n",
    "# N_FOLDS = 5 #! Validation set not created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dba8f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x, y):\n",
    "    # Unfold the tensor with a sliding window\n",
    "    output_x = x.unfold(1, SAMPLE_LEN, STRIDE)\n",
    "    \n",
    "    # Reshape the output tensor to be 2D\n",
    "    output_x = output_x.contiguous().view(-1, SAMPLE_LEN)\n",
    "    \n",
    "    # Calculate number of windows per sample\n",
    "    windows_per_sample = output_x.size(0) // y.size(0)\n",
    "    \n",
    "    # Repeat y values for each sub-sample\n",
    "    output_y = y.repeat_interleave(windows_per_sample)\n",
    "    \n",
    "    return output_x, output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e72731af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[-0.0488,  0.2167,  0.2350,  ...,  0.3876,  0.0336, -3.3417],\n",
      "        [ 0.1068,  0.6622,  0.0427,  ...,  0.0153, -0.1404, -0.2167],\n",
      "        [-0.1617, -0.1038,  0.0793,  ..., -0.0488,  0.0580,  0.4120],\n",
      "        ...,\n",
      "        [-0.0763, -0.2197, -0.3296,  ...,  0.3693,  0.0702, -0.2289],\n",
      "        [-0.5249, -0.4517, -0.4395,  ..., -1.0101, -1.1383, -0.1617],\n",
      "        [ 0.0732,  0.0122, -0.0305,  ..., -0.0153, -0.3479, -0.3235]],\n",
      "       dtype=torch.float64), 'y': tensor([0., 0., 0.,  ..., 4., 4., 4.], dtype=torch.float64)}\n",
      "torch.Size([24300, 1024])\n",
      "torch.Size([24300])\n"
     ]
    }
   ],
   "source": [
    "Real_Normal[\"x\"], Real_Normal[\"y\"] = sample(Real_Normal[\"x\"], Real_Normal[\"y\"])\n",
    "Real_Rotate[\"x\"], Real_Rotate[\"y\"] = sample(Real_Rotate[\"x\"], Real_Rotate[\"y\"])\n",
    "Real_Load[\"x\"], Real_Load[\"y\"] = sample(Real_Load[\"x\"], Real_Load[\"y\"])\n",
    "Real_Radial[\"x\"], Real_Radial[\"y\"] = sample(Real_Radial[\"x\"], Real_Radial[\"y\"])\n",
    "\n",
    "Artificial_Normal[\"x\"], Artificial_Normal[\"y\"] = sample(Artificial_Normal[\"x\"], Artificial_Normal[\"y\"])\n",
    "Artificial_Rotate[\"x\"], Artificial_Rotate[\"y\"] = sample(Artificial_Rotate[\"x\"], Artificial_Rotate[\"y\"])\n",
    "Artificial_Load[\"x\"], Artificial_Load[\"y\"] = sample(Artificial_Load[\"x\"], Artificial_Load[\"y\"])\n",
    "Artificial_Radial[\"x\"], Artificial_Radial[\"y\"] = sample(Artificial_Radial[\"x\"], Artificial_Radial[\"y\"])\n",
    "\n",
    "print(Real_Normal)\n",
    "print(Real_Normal[\"x\"].shape)\n",
    "print(Real_Normal[\"y\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8845c783",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa6d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y):\n",
    "    total_size = len(x)\n",
    "    train_size = int(0.8 * total_size)  # 80% of the dataset\n",
    "    test_size = total_size - train_size\n",
    "    \n",
    "    indices = torch.randperm(total_size)\n",
    "    \n",
    "    train_indices = indices[:train_size]\n",
    "    test_indices = indices[train_size:]\n",
    "\n",
    "    x_train = x[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "\n",
    "    x_test = x[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21e43c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19440, 1024]), torch.Size([19440])\n",
      "torch.Size([4860, 1024]), torch.Size([4860])\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "Real_Normal_x_train, Real_Normal_y_train, Real_Normal_x_test, Real_Normal_y_test = train_test_split(Real_Normal[\"x\"], Real_Normal[\"y\"])\n",
    "Real_Rotate_x_train, Real_Rotate_y_train, Real_Rotate_x_test, Real_Rotate_y_test = train_test_split(Real_Rotate[\"x\"], Real_Rotate[\"y\"])\n",
    "Real_Load_x_train, Real_Load_y_train, Real_Load_x_test, Real_Load_y_test = train_test_split(Real_Load[\"x\"], Real_Load[\"y\"])\n",
    "Real_Radial_x_train, Real_Radial_y_train, Real_Radial_x_test, Real_Radial_y_test = train_test_split(Real_Radial[\"x\"], Real_Radial[\"y\"])\n",
    "\n",
    "Artificial_Normal_x_train, Artificial_Normal_y_train, Artificial_Normal_x_test, Artificial_Normal_y_test = train_test_split(Artificial_Normal[\"x\"], Artificial_Normal[\"y\"])\n",
    "Artificial_Rotate_x_train, Artificial_Rotate_y_train, Artificial_Rotate_x_test, Artificial_Rotate_y_test = train_test_split(Artificial_Rotate[\"x\"], Artificial_Rotate[\"y\"])\n",
    "Artificial_Load_x_train, Artificial_Load_y_train, Artificial_Load_x_test, Artificial_Load_y_test = train_test_split(Artificial_Load[\"x\"], Artificial_Load[\"y\"])\n",
    "Artificial_Radial_x_train, Artificial_Radial_y_train, Artificial_Radial_x_test, Artificial_Radial_y_test = train_test_split(Artificial_Radial[\"x\"], Artificial_Radial[\"y\"])\n",
    "\n",
    "print(f\"{Real_Normal_x_train.shape}, {Real_Normal_y_train.shape}\")\n",
    "print(f\"{Real_Normal_x_test.shape}, {Real_Normal_y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f284f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real domain\n",
    "Real_Normal_train = {\"samples\": Real_Normal_x_train, \"labels\": Real_Normal_y_train}\n",
    "Real_Normal_test = {\"samples\": Real_Normal_x_test, \"labels\": Real_Normal_y_test}\n",
    "\n",
    "Real_Rotate_train = {\"samples\": Real_Rotate_x_train, \"labels\": Real_Rotate_y_train}\n",
    "Real_Rotate_test = {\"samples\": Real_Rotate_x_test, \"labels\": Real_Rotate_y_test}\n",
    "\n",
    "Real_Load_train = {\"samples\": Real_Load_x_train, \"labels\": Real_Load_y_train}\n",
    "Real_Load_test = {\"samples\": Real_Load_x_test, \"labels\": Real_Load_y_test}\n",
    "\n",
    "Real_Radial_train = {\"samples\": Real_Radial_x_train, \"labels\": Real_Radial_y_train}\n",
    "Real_Radial_test = {\"samples\": Real_Radial_x_test, \"labels\": Real_Radial_y_test}\n",
    "\n",
    "# Artificial domain\n",
    "Artificial_Normal_train = {\"samples\": Artificial_Normal_x_train, \"labels\": Artificial_Normal_y_train}\n",
    "Artificial_Normal_test = {\"samples\": Artificial_Normal_x_test, \"labels\": Artificial_Normal_y_test}\n",
    "\n",
    "Artificial_Rotate_train = {\"samples\": Artificial_Rotate_x_train, \"labels\": Artificial_Rotate_y_train}\n",
    "Artificial_Rotate_test = {\"samples\": Artificial_Rotate_x_test, \"labels\": Artificial_Rotate_y_test}\n",
    "\n",
    "Artificial_Load_train = {\"samples\": Artificial_Load_x_train, \"labels\": Artificial_Load_y_train}\n",
    "Artificial_Load_test = {\"samples\": Artificial_Load_x_test, \"labels\": Artificial_Load_y_test}\n",
    "\n",
    "Artificial_Radial_train = {\"samples\": Artificial_Radial_x_train, \"labels\": Artificial_Radial_y_train}\n",
    "Artificial_Radial_test = {\"samples\": Artificial_Radial_x_test, \"labels\": Artificial_Radial_y_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4fd773",
   "metadata": {},
   "source": [
    "# Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f77c7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parent directory\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "Real_dir = os.path.join(parent_dir, \"dataset\", \"PU_Real\")\n",
    "Artificial_dir = os.path.join(parent_dir, \"dataset\", \"PU_Artificial\")\n",
    "\n",
    "if not os.path.exists(Real_dir):\n",
    "    os.makedirs(Real_dir)\n",
    "\n",
    "if not os.path.exists(Artificial_dir):\n",
    "    os.makedirs(Artificial_dir)\n",
    "\n",
    "torch.save(Real_Normal_train, os.path.join(Real_dir, \"train_Normal.pt\"))\n",
    "torch.save(Real_Normal_test, os.path.join(Real_dir, \"test_Normal.pt\"))\n",
    "torch.save(Real_Rotate_train, os.path.join(Real_dir, \"train_Rotate.pt\"))\n",
    "torch.save(Real_Rotate_test, os.path.join(Real_dir, \"test_Rotate.pt\"))\n",
    "torch.save(Real_Load_train, os.path.join(Real_dir, \"train_Load.pt\"))\n",
    "torch.save(Real_Load_test, os.path.join(Real_dir, \"test_Load.pt\"))\n",
    "torch.save(Real_Radial_train, os.path.join(Real_dir, \"train_Radial.pt\"))\n",
    "torch.save(Real_Radial_test, os.path.join(Real_dir, \"test_Radial.pt\"))\n",
    "\n",
    "torch.save(Artificial_Normal_train, os.path.join(Artificial_dir, \"train_Normal.pt\"))\n",
    "torch.save(Artificial_Normal_test, os.path.join(Artificial_dir, \"test_Normal.pt\"))\n",
    "torch.save(Artificial_Rotate_train, os.path.join(Artificial_dir, \"train_Rotate.pt\"))\n",
    "torch.save(Artificial_Rotate_test, os.path.join(Artificial_dir, \"test_Rotate.pt\"))\n",
    "torch.save(Artificial_Load_train, os.path.join(Artificial_dir, \"train_Load.pt\"))\n",
    "torch.save(Artificial_Load_test, os.path.join(Artificial_dir, \"test_Load.pt\"))\n",
    "torch.save(Artificial_Radial_train, os.path.join(Artificial_dir, \"train_Radial.pt\"))\n",
    "torch.save(Artificial_Radial_test, os.path.join(Artificial_dir, \"test_Radial.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
